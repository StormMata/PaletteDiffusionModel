{
    "name":          "01",                                             // Experiment name
    "wandb_project": "inpainting_test",                                      // Weights and Biases experiment name (why is this different)
    "gpu_ids":       [0,
                      1,
                      2,
                      3],                                              // gpu ids list, default is single 0
    "seed" :          2,                                               // random seed, seed <0 represents randomization not used 
    "finetune_norm":  false,                                           // find the parameters to optimize
    "datatype":       "2d_numpy",                                      // "image", "2d_numpy", "3d_numpy" (2d_numpy is okay for 2D PyTorch tensors!)

    "path": {                                                          // set every part file path
        "base_dir":        "/scratch/smata/PaletteDiffusionModel",                 // base path for all log except resume_state
        "code":            "code",                                     // code backup
        "tb_logger":       "tb_logger",                                // path of tensorboard logger
        "results":         "results",
        "checkpoint":      "checkpoint",
        // "resume_state": "/scratch/smata/PaletteDiffusionModel/checkpoint" 
        "resume_state":    null                                        // ex: 100, loading .state  and .pth from given epoch and iteration
    },

    "datasets": {                                                      // TRAIN SETTINGS
        "train": { 
            "which_dataset": {                                         // import designated dataset using arguments 
                "name": [           "data.dataset", 
                                    "InpaintDataset"],            // import Dataset() class / function(not recommend) from data.dataset.py (default is [data.dataset.py])
                "args":{                                               // arguments to initialize dataset
                    "data_root":    "/scratch/smata/PaletteDiffusionModel/data/flist/sector_1/train_and_val.flist",
                    "data_len":     -1,                                // Full dataset?+
                    "mask_config": {
                        "mask_mode": "bottom"
                    },
                    "data_bounds": [
                        -14.145477391842705,
                        25.55866949139715,
                        -20.310099955027688,
                        27.949959019988107,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
        ],
        "image_size": [
                        96,
                        200
        ]
    } 
},
            "dataloader":{
                "validation_split": 509,                               // percent or number 
                "args":{                                               // arguments to initialize train_dataloader
                    "batch_size":   3,                                // batch size in each gpu
                    "num_workers":  4,                                 // Same as number of GPUs?
                    "shuffle":      true,                              // Shuffle at each epoch
                    "pin_memory":   true,
                    "drop_last":    true                               // Drop incomplete batch
                },
                "val_args":{                                           // arguments to initialize valid_dataloader
                    "batch_size":   1,                                // batch size in each gpu
                    "num_workers":  4,
                    "shuffle":      false,
                    "pin_memory":   true,
                    "drop_last":    false
                }
            }
        },
        "test": {                                                      // TEST SETTINGS
            "which_dataset": {
                "name":             "InpaintDataset",             // import Dataset() class / function(not recommend) from default file
                "args":{
                    "data_root":    "/scratch/smata/PaletteDiffusionModel/data/flist/sector_1/test.flist",
                    "data_len":     -1,                                // Use full data set
                    "mask_config": {
                        "mask_mode": "bottom"
                    },
                    "data_bounds": [
                        -14.145477391842705,
                        25.55866949139715,
                        -20.310099955027688,
                        27.949959019988107,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                    ],
                    "image_size": [
                        96,
                        200
                                  ]     
                }
            },
            "dataloader":{
                "args":{
                    "batch_size": 8,
                    "num_workers": 4,
                    "pin_memory": true
                }
            }
        }
    },

    "model": { // networks/metrics/losses/optimizers/lr_schedulers is a list and model is a dict
        "which_model": { // import designated  model(trainer) using arguments 
            "name": ["models.model", "Palette"], // import Model() class / function(not recommend) from models.model.py (default is [models.model.py])
            "args": {
                "sample_num": 8, // process of each image
                "task": "inpainting",
                "ema_scheduler": {
                    "ema_start": 1,
                    "ema_iter": 1,
                    "ema_decay": 0.9999
                },
                "optimizers": [
                    { "lr": 5e-5, "weight_decay": 0}
                ]
            }
        }, 
        "which_networks": [ // import designated list of networks using arguments
            {
                "name": ["models.network", "Network"], // import Network() class / function(not recommend) from default file (default is [models/network.py]) 
                "args": { // arguments to initialize network
                    "init_type": "kaiming", // method can be [normal | xavier| xavier_uniform | kaiming | orthogonal], default is kaiming
                    "module_name": "guided_diffusion", // sr3 | guided_diffusion
                    "unet": {
                        "in_channel": 6,
                        "out_channel": 3,
                        "inner_channel": 64,
                        "channel_mults": [
                            1,
                            2,
                            4,
                            8
                        ],
                        "attn_res": [
                            // 32,
                            16
                            // 8
                        ],
                        "num_head_channels": 32,
                        "res_blocks": 2,
                        "dropout": 0.2,
                        "image_size": [
                            96, 
                            200
                        ]
                    },
                    "beta_schedule": {
                        "train": {
                            "schedule": "linear",
                            "n_timestep": 2000,
                            // "n_timestep": 5, // debug
                            "linear_start": 1e-6,
                            "linear_end": 0.01
                        },
                        "test": {
                            "schedule": "linear",
                            "n_timestep": 1000,
                            "linear_start": 1e-4,
                            "linear_end": 0.09
                        }
                    }
                }
            }
        ],
        "which_losses": [ // import designated list of losses without arguments
            "mse_loss" // import mse_loss() function/class from default file (default is [models/losses.py]), equivalent to { "name": "mse_loss", "args":{}}
        ],
        "which_metrics": [ // import designated list of metrics without arguments
            "mae" // import mae() function/class from default file (default is [models/metrics.py]), equivalent to { "name": "mae", "args":{}}
        ]
    },

    "train": { // arguments for basic training
        "n_epoch": 1e8, // max epochs, not limited now
        "n_iter": 1e8, // max interations
        "val_epoch": 1, // valdation every specified number of epochs
        "save_checkpoint_epoch": 1,
        "log_iter": 1e4, // log every specified number of iterations
        "tensorboard" : true // tensorboardX enable
    },
    
    "debug": { // arguments in debug mode, which will replace arguments in train
        "val_epoch": 1,
        "save_checkpoint_epoch": 1,
        "log_iter": 10,
        "debug_split": 50 // percent or number, change the size of dataloder to debug_split.
    }
}
